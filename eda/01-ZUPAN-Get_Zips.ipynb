{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from math import radians, cos, sin, asin, sqrt\n",
    "import datetime\n",
    "from typing import List\n",
    "# import geopy\n",
    "# import geopy.distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ytd_data_path = os.path.join('..', 'data','NYPD_Arrest_Data__Year_to_Date_.csv')\n",
    "crime_df = pd.read_csv(ytd_data_path, nrows=50)\n",
    "print(crime_df.shape)\n",
    "crime_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df_path: str = os.path.join('..', 'data', 'NYPD_Arrests_Data__Historic_.csv')\n",
    "sample_df = pd.read_csv(full_df_path, parse_dates=[1], infer_datetime_format=True, nrows=5)\n",
    "chunksize: int = 10 ** 5\n",
    "column_names= list(sample_df)\n",
    "\n",
    "def parse_crime_df(file_path: str, year: int, chunksize: int, column_names: List[str]) -> pd.DataFrame:\n",
    "    \"\"\"Reads the csv in `chunksize` pieces.  Filters csv to only keep crimes committed in `year`.\n",
    "       Returns a pandas dataframe with all crimes from the selected year.\n",
    "    \"\"\"\n",
    "    base_df: pd.DataFrame = pd.DataFrame(columns=column_names)\n",
    "    with pd.read_csv(full_df_path, parse_dates=[1], infer_datetime_format=True, chunksize=chunksize) as reader:\n",
    "        for chunk in reader:\n",
    "            filtered_df = chunk[chunk.ARREST_DATE.dt.year == year].copy()\n",
    "            base_df = base_df.append(filtered_df)\n",
    "    return base_df\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Start Time: {datetime.datetime.now()}\\n')\n",
    "\n",
    "filtered_2018_df = parse_crime_df(file_path=full_df_path, year=2018, chunksize=chunksize)\n",
    "\n",
    "print(f'Finish Time: {datetime.datetime.now()}\\n')\n",
    "\n",
    "print(f'DF shape: {filtered_2018_df.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Start Time: {datetime.datetime.now()}\\n')\n",
    "\n",
    "filtered_2019_df = parse_crime_df(file_path=full_df_path, year=2019, chunksize=chunksize)\n",
    "\n",
    "print(f'Finish Time: {datetime.datetime.now()}\\n')\n",
    "\n",
    "print(f'DF shape: {filtered_2019_df.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Start Time: {datetime.datetime.now()}\\n')\n",
    "\n",
    "filtered_2017_df = parse_crime_df(file_path=full_df_path, year=2017, chunksize=chunksize)\n",
    "\n",
    "print(f'Finish Time: {datetime.datetime.now()}\\n')\n",
    "\n",
    "print(f'DF shape: {filtered_2017_df.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_2017_df.reset_index(inplace=True, drop=True)\n",
    "\n",
    "filtered_2018_df.reset_index(inplace=True, drop=True)\n",
    "\n",
    "filtered_2019_df.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ny_addresses = pd.read_csv(os.path.join('..', 'data', 'city_of_new_york.csv'))\n",
    "ny_addresses.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try 1: too slow\n",
    "\n",
    "# import geopy\n",
    "# import geopy.geolocator\n",
    "\n",
    "# def get_zipcode(df: pd.DataFrame, geolocator: geopy.geolocotor, lat_field: str, lon_field: str):\n",
    "#     \"\"\"Given a Pandas DataFrame, apply the geopy geolocator to find the zip code of the record\"\"\"\n",
    "#     location = geolocator.reverse((df[lat_field], df[lon_field]))\n",
    "#     return location.raw['address']['postcode']\n",
    "\n",
    "# geolocator = geopy.Nominatim(user_agent='umads_591_tz')\n",
    "\n",
    "# print(f'Time: {datetime.datetime.now()}\\n')\n",
    "# zipcodes = crime_df.apply(get_zipcode, axis=1, geolocator=geolocator, lat_field='Latitude', lon_field='Longitude')\n",
    "# print(f'Time: {datetime.datetime.now()}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try 2: still too slow\n",
    "# brute force\n",
    "# \n",
    "def get_crime_zip_codes(crime_df: pd.DataFrame, address_lookup_df: pd.DataFrame, min_distance_threshold: float = 1.0, \n",
    "                        print_rate:int = 1, verbose: bool = False, save_checkpoints:bool = False):\n",
    "    \"\"\"For every record in the arrest data set, find the first record in the address data set\n",
    "        that is less than the `min_distance_threshold` and return the zip code for that address.\n",
    "    \"\"\"\n",
    "    for crime_idx, crime in crime_df.iterrows():\n",
    "        if crime_idx % print_rate == 0:\n",
    "            print(f'Starting on crime index {crime_idx}')\n",
    "            print(f'Time: {datetime.datetime.now()}\\n')\n",
    "        if crime_idx % 10000 == 0 and save_checkpoints:\n",
    "            print(f'Checkpointing on crime index {crime_idx}')\n",
    "            crime_df.to_csv(os.path.join('..', 'data', 'cleaned_data', 'ny_crimes_2018.csv'), index=False)\n",
    "        crime_lat = crime.Latitude\n",
    "        crime_long = crime.Longitude\n",
    "        for address_idx, address in address_lookup_df.iterrows():\n",
    "            address_lat = address.LAT\n",
    "            address_long = address.LON\n",
    "            distance = geopy.distance.distance((crime.Latitude, crime.Longitude), (address.LAT, address.LON)).miles\n",
    "            if verbose:\n",
    "                print(f'Address: {address_idx} Distance: {distance}')\n",
    "            if distance < min_distance_threshold:\n",
    "                crime_df.loc[crime_idx, 'crime_zip_code'] = address.POSTCODE\n",
    "                break\n",
    "    return crime_df\n",
    "\n",
    "get_crime_zip_codes(crime_df=filtered_2018_df, address_lookup_df=ny_addresses, min_distance_threshold=1.0, print_rate=1, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAVE BUT DOES NOT WORK\n",
    "# Fast but no correct\n",
    "\n",
    "# import numpy as np\n",
    "# crime_coords = np.array(filtered_2018_df[['Latitude', 'Longitude']])\n",
    "# address_coords = np.array(ny_addresses[['LAT', 'LON']])\n",
    "\n",
    "# # crime_df_shape = crime_coords.shape[0]\n",
    "\n",
    "# max_cos_idx = []\n",
    "\n",
    "# for crime in crime_coords[:5]:\n",
    "        \n",
    "#     cosine_similarity = np.dot(crime, address_coords.T)/linalg.norm(crime)/linalg.norm(address_coords)\n",
    "#     max_cos_idx.append(cosine_similarity.argmax())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filtered_2018_df_sample = filtered_2018_df.loc[:10,:].copy()\n",
    "# get_crime_zip_codes(crime_df=filtered_2018_df_sample, address_lookup_df=ny_addresses, min_distance_threshold=1.0, print_rate=1, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# updated_2018_df = get_crime_zip_codes(crime_df=filtered_2018_df, address_lookup_df=ny_addresses, min_distance_threshold=1.0, \n",
    "#                                       print_rate=1000, verbose=False, save_checkpoints=True)\n",
    "\n",
    "# updated_2018_df.to_csv(os.path.join('..', 'data', 'cleaned_data', 'ny_crimes_2018.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# updated_2018_df = pd.read_csv(os.path.join('..', 'data', 'cleaned_data', 'ny_crimes_2018.csv'))\n",
    "# updated_2018_df[updated_2018_df.crime_zip_code.isna()].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def haversine(lat1, lon1, lat2, lon2):\n",
    "    \"\"\"\n",
    "    Calculate the great circle distance between two points \n",
    "    on the earth (specified in decimal degrees)\n",
    "    \n",
    "    From stackoverflow:\n",
    "    https://stackoverflow.com/questions/4913349/haversine-formula-in-python-bearing-and-distance-between-two-gps-points\n",
    "    \"\"\"\n",
    "    # convert decimal degrees to radians \n",
    "    lon1, lat1, lon2, lat2 = map(radians, [lon1, lat1, lon2, lat2])\n",
    "    # haversine formula \n",
    "    dlon = lon2 - lon1 \n",
    "    dlat = lat2 - lat1 \n",
    "    a = sin(dlat/2)**2 + cos(lat1) * cos(lat2) * sin(dlon/2)**2\n",
    "    c = 2 * asin(sqrt(a)) \n",
    "    # radius of earth in miles\n",
    "    dist = 3956 * c\n",
    "    return dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing, put into function later\n",
    "\n",
    "# %%time\n",
    "\n",
    "# crime_coords = np.array(filtered_2018_df[['Latitude', 'Longitude']])\n",
    "# address_coords = np.array(ny_addresses[['LAT', 'LON']])\n",
    "\n",
    "# max_cos_idx = []\n",
    "# zip_code_list = []\n",
    "\n",
    "# print(f'Start Time: {datetime.datetime.now()}\\n')\n",
    "\n",
    "# for crime in crime_coords:\n",
    "#     for idx, address in enumerate(address_coords):\n",
    "#         h_dist = haversine(crime[0], crime[1], address[0], address[1])\n",
    "#         if h_dist < 0.5:\n",
    "#             max_cos_idx.append(idx)\n",
    "#             zip_code_list.append(int(ny_addresses.loc[idx, 'POSTCODE']))\n",
    "#             break\n",
    "            \n",
    "# print(f'Finish Time: {datetime.datetime.now()}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_crime_zips(crime_coords, address_coords, ny_addresses):\n",
    "    \"\"\"\"\"\"\n",
    "    max_cos_idx = []\n",
    "    zip_code_list = []\n",
    "    \n",
    "    for crime in crime_coords:\n",
    "        for idx, address in enumerate(address_coords):\n",
    "            h_dist = haversine(crime[0], crime[1], address[0], address[1])\n",
    "            if h_dist < 0.5:\n",
    "                max_cos_idx.append(idx)\n",
    "                zip_code_list.append(int(ny_addresses.loc[idx, 'POSTCODE']))\n",
    "                break\n",
    "        # this will be triggered if all ny addresses were checked and nothing within\n",
    "        # the min diff was found\n",
    "        if h_dist > 0.5:\n",
    "            max_cos_idx.append(0)\n",
    "            zip_code_list.append(0)\n",
    "                \n",
    "    return max_cos_idx, zip_code_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crime_coords = np.array(filtered_2018_df[['Latitude', 'Longitude']])\n",
    "address_coords = np.array(ny_addresses[['LAT', 'LON']])\n",
    "\n",
    "_, zips = get_crime_zips(crime_coords, address_coords, ny_addresses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(filtered_2018_df) == len(zips)\n",
    "\n",
    "filtered_2018_df['zip_code'] = zips\n",
    "filtered_2018_df.to_csv(os.path.join('..', 'data', 'cleaned_data', 'ny_crimes_2018.csv'), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2017"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crime_coords = np.array(filtered_2017_df[['Latitude', 'Longitude']])\n",
    "address_coords = np.array(ny_addresses[['LAT', 'LON']])\n",
    "\n",
    "_, zips = get_crime_zips(crime_coords, address_coords, ny_addresses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(filtered_2017_df) == len(zips)\n",
    "\n",
    "filtered_2017_df['zip_code'] = zips\n",
    "filtered_2017_df.to_csv(os.path.join('..', 'data', 'cleaned_data', 'ny_crimes_2017.csv'), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crime_coords = np.array(filtered_2019_df[['Latitude', 'Longitude']])\n",
    "address_coords = np.array(ny_addresses[['LAT', 'LON']])\n",
    "\n",
    "_, zips = get_crime_zips(crime_coords, address_coords, ny_addresses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(filtered_2019_df) == len(zips)\n",
    "\n",
    "filtered_2019_df['zip_code'] = zips\n",
    "filtered_2019_df.to_csv(os.path.join('..', 'data', 'cleaned_data', 'ny_crimes_2019.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Things to do:\n",
    "\n",
    "1. Append zip code to every crime\n",
    "\n",
    "2. EDA/Summary stats on crime at the zip code level\n",
    "    * total counts\n",
    "    * counts by type\n",
    "    * crime by month/day of week\n",
    "\n",
    "3. Correlation between counts of crime and housing price\n",
    "    * year-to-year and lagged?\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For Write up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def haversine(lat1: float, lon1: float, lat2: float, lon2: float):\n",
    "    \"\"\"\n",
    "    Calculate the great circle distance between two points \n",
    "    on the earth (specified in decimal degrees)\n",
    "    \n",
    "    From stackoverflow:\n",
    "    https://stackoverflow.com/questions/4913349/haversine-formula-in-python-bearing-and-distance-between-two-gps-points\n",
    "    \"\"\"\n",
    "    # convert decimal degrees to radians \n",
    "    lon1, lat1, lon2, lat2 = map(radians, [lon1, lat1, lon2, lat2])\n",
    "    # haversine formula \n",
    "    dlon = lon2 - lon1 \n",
    "    dlat = lat2 - lat1 \n",
    "    a = sin(dlat/2)**2 + cos(lat1) * cos(lat2) * sin(dlon/2)**2\n",
    "    c = 2 * asin(sqrt(a)) \n",
    "    # radius of earth in miles\n",
    "    dist = 3956 * c\n",
    "    return dist\n",
    "\n",
    "def get_crime_zips(crime_coords: np.array, address_coords: np.array, ny_addresses: pd.DataFrame):\n",
    "    \"\"\"\"\"\"\n",
    "    max_cos_idx: List[float] = []\n",
    "    zip_code_list: List[float] = []\n",
    "    \n",
    "    for crime in crime_coords:\n",
    "        for idx, address in enumerate(address_coords):\n",
    "            h_dist = haversine(crime[0], crime[1], address[0], address[1])\n",
    "            if h_dist < 0.5:\n",
    "                max_cos_idx.append(idx)\n",
    "                zip_code_list.append(int(ny_addresses.loc[idx, 'POSTCODE']))\n",
    "                break\n",
    "        # this will be triggered if all ny addresses were checked and nothing within\n",
    "        # the min diff was found\n",
    "        if h_dist > 0.5:\n",
    "            max_cos_idx.append(0)\n",
    "            zip_code_list.append(0)\n",
    "                \n",
    "    return max_cos_idx, zip_code_list\n",
    "\n",
    "# select just the necssary columns from the two data frames\n",
    "crime_coords = np.array(filtered_2018_df[['Latitude', 'Longitude']])\n",
    "address_coords = np.array(ny_addresses[['LAT', 'LON']])\n",
    "\n",
    "# run function\n",
    "_, zips = get_crime_zips(crime_coords, address_coords, ny_addresses)\n",
    "\n",
    "# check the list returned is the same length as the original dataframe\n",
    "assert len(filtered_arrests_df) == len(zips)\n",
    "\n",
    "# assign the list of zips as a new column in the arrests dataframe\n",
    "filtered_arrests_df['zip_code'] = zips"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "umads_venv",
   "language": "python",
   "name": "umads_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
